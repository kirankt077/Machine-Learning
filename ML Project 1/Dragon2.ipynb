{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('C:\\\\Users\\\\KiranThakur\\\\Simplilearn_Scripts\\\\Prashant_Nair\\\\ML Project 1\\\\data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  PTRATIO  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "        B  LSTAT  MEDV  \n",
       "0  396.90   4.98  24.0  \n",
       "1  396.90   9.14  21.6  \n",
       "2  392.83   4.03  34.7  \n",
       "3  394.63   2.94  33.4  \n",
       "4  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.RM.fillna(data.RM.median(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 14 columns):\n",
      "CRIM       506 non-null float64\n",
      "ZN         506 non-null float64\n",
      "INDUS      506 non-null float64\n",
      "CHAS       506 non-null int64\n",
      "NOX        506 non-null float64\n",
      "RM         506 non-null float64\n",
      "AGE        506 non-null float64\n",
      "DIS        506 non-null float64\n",
      "RAD        506 non-null int64\n",
      "TAX        506 non-null int64\n",
      "PTRATIO    506 non-null float64\n",
      "B          506 non-null float64\n",
      "LSTAT      506 non-null float64\n",
      "MEDV       506 non-null float64\n",
      "dtypes: float64(11), int64(3)\n",
      "memory usage: 55.5 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
       "        4.9800e+00],\n",
       "       [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
       "        9.1400e+00],\n",
       "       [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
       "        4.0300e+00],\n",
       "       ...,\n",
       "       [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "        5.6400e+00],\n",
       "       [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
       "        6.4800e+00],\n",
       "       [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "        7.8800e+00]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = data.iloc[:,:-1].values\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[24. ],\n",
       "       [21.6],\n",
       "       [34.7],\n",
       "       [33.4],\n",
       "       [36.2],\n",
       "       [28.7],\n",
       "       [22.9],\n",
       "       [27.1],\n",
       "       [16.5],\n",
       "       [18.9],\n",
       "       [15. ],\n",
       "       [18.9],\n",
       "       [21.7],\n",
       "       [20.4],\n",
       "       [18.2],\n",
       "       [19.9],\n",
       "       [23.1],\n",
       "       [17.5],\n",
       "       [20.2],\n",
       "       [18.2],\n",
       "       [13.6],\n",
       "       [19.6],\n",
       "       [15.2],\n",
       "       [14.5],\n",
       "       [15.6],\n",
       "       [13.9],\n",
       "       [16.6],\n",
       "       [14.8],\n",
       "       [18.4],\n",
       "       [21. ],\n",
       "       [12.7],\n",
       "       [14.5],\n",
       "       [13.2],\n",
       "       [13.1],\n",
       "       [13.5],\n",
       "       [18.9],\n",
       "       [20. ],\n",
       "       [21. ],\n",
       "       [24.7],\n",
       "       [30.8],\n",
       "       [34.9],\n",
       "       [26.6],\n",
       "       [25.3],\n",
       "       [24.7],\n",
       "       [21.2],\n",
       "       [19.3],\n",
       "       [20. ],\n",
       "       [16.6],\n",
       "       [14.4],\n",
       "       [19.4],\n",
       "       [19.7],\n",
       "       [20.5],\n",
       "       [25. ],\n",
       "       [23.4],\n",
       "       [18.9],\n",
       "       [35.4],\n",
       "       [24.7],\n",
       "       [31.6],\n",
       "       [23.3],\n",
       "       [19.6],\n",
       "       [18.7],\n",
       "       [16. ],\n",
       "       [22.2],\n",
       "       [25. ],\n",
       "       [33. ],\n",
       "       [23.5],\n",
       "       [19.4],\n",
       "       [22. ],\n",
       "       [17.4],\n",
       "       [20.9],\n",
       "       [24.2],\n",
       "       [21.7],\n",
       "       [22.8],\n",
       "       [23.4],\n",
       "       [24.1],\n",
       "       [21.4],\n",
       "       [20. ],\n",
       "       [20.8],\n",
       "       [21.2],\n",
       "       [20.3],\n",
       "       [28. ],\n",
       "       [23.9],\n",
       "       [24.8],\n",
       "       [22.9],\n",
       "       [23.9],\n",
       "       [26.6],\n",
       "       [22.5],\n",
       "       [22.2],\n",
       "       [23.6],\n",
       "       [28.7],\n",
       "       [22.6],\n",
       "       [22. ],\n",
       "       [22.9],\n",
       "       [25. ],\n",
       "       [20.6],\n",
       "       [28.4],\n",
       "       [21.4],\n",
       "       [38.7],\n",
       "       [43.8],\n",
       "       [33.2],\n",
       "       [27.5],\n",
       "       [26.5],\n",
       "       [18.6],\n",
       "       [19.3],\n",
       "       [20.1],\n",
       "       [19.5],\n",
       "       [19.5],\n",
       "       [20.4],\n",
       "       [19.8],\n",
       "       [19.4],\n",
       "       [21.7],\n",
       "       [22.8],\n",
       "       [18.8],\n",
       "       [18.7],\n",
       "       [18.5],\n",
       "       [18.3],\n",
       "       [21.2],\n",
       "       [19.2],\n",
       "       [20.4],\n",
       "       [19.3],\n",
       "       [22. ],\n",
       "       [20.3],\n",
       "       [20.5],\n",
       "       [17.3],\n",
       "       [18.8],\n",
       "       [21.4],\n",
       "       [15.7],\n",
       "       [16.2],\n",
       "       [18. ],\n",
       "       [14.3],\n",
       "       [19.2],\n",
       "       [19.6],\n",
       "       [23. ],\n",
       "       [18.4],\n",
       "       [15.6],\n",
       "       [18.1],\n",
       "       [17.4],\n",
       "       [17.1],\n",
       "       [13.3],\n",
       "       [17.8],\n",
       "       [14. ],\n",
       "       [14.4],\n",
       "       [13.4],\n",
       "       [15.6],\n",
       "       [11.8],\n",
       "       [13.8],\n",
       "       [15.6],\n",
       "       [14.6],\n",
       "       [17.8],\n",
       "       [15.4],\n",
       "       [21.5],\n",
       "       [19.6],\n",
       "       [15.3],\n",
       "       [19.4],\n",
       "       [17. ],\n",
       "       [15.6],\n",
       "       [13.1],\n",
       "       [41.3],\n",
       "       [24.3],\n",
       "       [23.3],\n",
       "       [27. ],\n",
       "       [50. ],\n",
       "       [50. ],\n",
       "       [50. ],\n",
       "       [22.7],\n",
       "       [25. ],\n",
       "       [50. ],\n",
       "       [23.8],\n",
       "       [23.8],\n",
       "       [22.3],\n",
       "       [17.4],\n",
       "       [19.1],\n",
       "       [23.1],\n",
       "       [23.6],\n",
       "       [22.6],\n",
       "       [29.4],\n",
       "       [23.2],\n",
       "       [24.6],\n",
       "       [29.9],\n",
       "       [37.2],\n",
       "       [39.8],\n",
       "       [36.2],\n",
       "       [37.9],\n",
       "       [32.5],\n",
       "       [26.4],\n",
       "       [29.6],\n",
       "       [50. ],\n",
       "       [32. ],\n",
       "       [29.8],\n",
       "       [34.9],\n",
       "       [37. ],\n",
       "       [30.5],\n",
       "       [36.4],\n",
       "       [31.1],\n",
       "       [29.1],\n",
       "       [50. ],\n",
       "       [33.3],\n",
       "       [30.3],\n",
       "       [34.6],\n",
       "       [34.9],\n",
       "       [32.9],\n",
       "       [24.1],\n",
       "       [42.3],\n",
       "       [48.5],\n",
       "       [50. ],\n",
       "       [22.6],\n",
       "       [24.4],\n",
       "       [22.5],\n",
       "       [24.4],\n",
       "       [20. ],\n",
       "       [21.7],\n",
       "       [19.3],\n",
       "       [22.4],\n",
       "       [28.1],\n",
       "       [23.7],\n",
       "       [25. ],\n",
       "       [23.3],\n",
       "       [28.7],\n",
       "       [21.5],\n",
       "       [23. ],\n",
       "       [26.7],\n",
       "       [21.7],\n",
       "       [27.5],\n",
       "       [30.1],\n",
       "       [44.8],\n",
       "       [50. ],\n",
       "       [37.6],\n",
       "       [31.6],\n",
       "       [46.7],\n",
       "       [31.5],\n",
       "       [24.3],\n",
       "       [31.7],\n",
       "       [41.7],\n",
       "       [48.3],\n",
       "       [29. ],\n",
       "       [24. ],\n",
       "       [25.1],\n",
       "       [31.5],\n",
       "       [23.7],\n",
       "       [23.3],\n",
       "       [22. ],\n",
       "       [20.1],\n",
       "       [22.2],\n",
       "       [23.7],\n",
       "       [17.6],\n",
       "       [18.5],\n",
       "       [24.3],\n",
       "       [20.5],\n",
       "       [24.5],\n",
       "       [26.2],\n",
       "       [24.4],\n",
       "       [24.8],\n",
       "       [29.6],\n",
       "       [42.8],\n",
       "       [21.9],\n",
       "       [20.9],\n",
       "       [44. ],\n",
       "       [50. ],\n",
       "       [36. ],\n",
       "       [30.1],\n",
       "       [33.8],\n",
       "       [43.1],\n",
       "       [48.8],\n",
       "       [31. ],\n",
       "       [36.5],\n",
       "       [22.8],\n",
       "       [30.7],\n",
       "       [50. ],\n",
       "       [43.5],\n",
       "       [20.7],\n",
       "       [21.1],\n",
       "       [25.2],\n",
       "       [24.4],\n",
       "       [35.2],\n",
       "       [32.4],\n",
       "       [32. ],\n",
       "       [33.2],\n",
       "       [33.1],\n",
       "       [29.1],\n",
       "       [35.1],\n",
       "       [45.4],\n",
       "       [35.4],\n",
       "       [46. ],\n",
       "       [50. ],\n",
       "       [32.2],\n",
       "       [22. ],\n",
       "       [20.1],\n",
       "       [23.2],\n",
       "       [22.3],\n",
       "       [24.8],\n",
       "       [28.5],\n",
       "       [37.3],\n",
       "       [27.9],\n",
       "       [23.9],\n",
       "       [21.7],\n",
       "       [28.6],\n",
       "       [27.1],\n",
       "       [20.3],\n",
       "       [22.5],\n",
       "       [29. ],\n",
       "       [24.8],\n",
       "       [22. ],\n",
       "       [26.4],\n",
       "       [33.1],\n",
       "       [36.1],\n",
       "       [28.4],\n",
       "       [33.4],\n",
       "       [28.2],\n",
       "       [22.8],\n",
       "       [20.3],\n",
       "       [16.1],\n",
       "       [22.1],\n",
       "       [19.4],\n",
       "       [21.6],\n",
       "       [23.8],\n",
       "       [16.2],\n",
       "       [17.8],\n",
       "       [19.8],\n",
       "       [23.1],\n",
       "       [21. ],\n",
       "       [23.8],\n",
       "       [23.1],\n",
       "       [20.4],\n",
       "       [18.5],\n",
       "       [25. ],\n",
       "       [24.6],\n",
       "       [23. ],\n",
       "       [22.2],\n",
       "       [19.3],\n",
       "       [22.6],\n",
       "       [19.8],\n",
       "       [17.1],\n",
       "       [19.4],\n",
       "       [22.2],\n",
       "       [20.7],\n",
       "       [21.1],\n",
       "       [19.5],\n",
       "       [18.5],\n",
       "       [20.6],\n",
       "       [19. ],\n",
       "       [18.7],\n",
       "       [32.7],\n",
       "       [16.5],\n",
       "       [23.9],\n",
       "       [31.2],\n",
       "       [17.5],\n",
       "       [17.2],\n",
       "       [23.1],\n",
       "       [24.5],\n",
       "       [26.6],\n",
       "       [22.9],\n",
       "       [24.1],\n",
       "       [18.6],\n",
       "       [30.1],\n",
       "       [18.2],\n",
       "       [20.6],\n",
       "       [17.8],\n",
       "       [21.7],\n",
       "       [22.7],\n",
       "       [22.6],\n",
       "       [25. ],\n",
       "       [19.9],\n",
       "       [20.8],\n",
       "       [16.8],\n",
       "       [21.9],\n",
       "       [27.5],\n",
       "       [21.9],\n",
       "       [23.1],\n",
       "       [50. ],\n",
       "       [50. ],\n",
       "       [50. ],\n",
       "       [50. ],\n",
       "       [50. ],\n",
       "       [13.8],\n",
       "       [13.8],\n",
       "       [15. ],\n",
       "       [13.9],\n",
       "       [13.3],\n",
       "       [13.1],\n",
       "       [10.2],\n",
       "       [10.4],\n",
       "       [10.9],\n",
       "       [11.3],\n",
       "       [12.3],\n",
       "       [ 8.8],\n",
       "       [ 7.2],\n",
       "       [10.5],\n",
       "       [ 7.4],\n",
       "       [10.2],\n",
       "       [11.5],\n",
       "       [15.1],\n",
       "       [23.2],\n",
       "       [ 9.7],\n",
       "       [13.8],\n",
       "       [12.7],\n",
       "       [13.1],\n",
       "       [12.5],\n",
       "       [ 8.5],\n",
       "       [ 5. ],\n",
       "       [ 6.3],\n",
       "       [ 5.6],\n",
       "       [ 7.2],\n",
       "       [12.1],\n",
       "       [ 8.3],\n",
       "       [ 8.5],\n",
       "       [ 5. ],\n",
       "       [11.9],\n",
       "       [27.9],\n",
       "       [17.2],\n",
       "       [27.5],\n",
       "       [15. ],\n",
       "       [17.2],\n",
       "       [17.9],\n",
       "       [16.3],\n",
       "       [ 7. ],\n",
       "       [ 7.2],\n",
       "       [ 7.5],\n",
       "       [10.4],\n",
       "       [ 8.8],\n",
       "       [ 8.4],\n",
       "       [16.7],\n",
       "       [14.2],\n",
       "       [20.8],\n",
       "       [13.4],\n",
       "       [11.7],\n",
       "       [ 8.3],\n",
       "       [10.2],\n",
       "       [10.9],\n",
       "       [11. ],\n",
       "       [ 9.5],\n",
       "       [14.5],\n",
       "       [14.1],\n",
       "       [16.1],\n",
       "       [14.3],\n",
       "       [11.7],\n",
       "       [13.4],\n",
       "       [ 9.6],\n",
       "       [ 8.7],\n",
       "       [ 8.4],\n",
       "       [12.8],\n",
       "       [10.5],\n",
       "       [17.1],\n",
       "       [18.4],\n",
       "       [15.4],\n",
       "       [10.8],\n",
       "       [11.8],\n",
       "       [14.9],\n",
       "       [12.6],\n",
       "       [14.1],\n",
       "       [13. ],\n",
       "       [13.4],\n",
       "       [15.2],\n",
       "       [16.1],\n",
       "       [17.8],\n",
       "       [14.9],\n",
       "       [14.1],\n",
       "       [12.7],\n",
       "       [13.5],\n",
       "       [14.9],\n",
       "       [20. ],\n",
       "       [16.4],\n",
       "       [17.7],\n",
       "       [19.5],\n",
       "       [20.2],\n",
       "       [21.4],\n",
       "       [19.9],\n",
       "       [19. ],\n",
       "       [19.1],\n",
       "       [19.1],\n",
       "       [20.1],\n",
       "       [19.9],\n",
       "       [19.6],\n",
       "       [23.2],\n",
       "       [29.8],\n",
       "       [13.8],\n",
       "       [13.3],\n",
       "       [16.7],\n",
       "       [12. ],\n",
       "       [14.6],\n",
       "       [21.4],\n",
       "       [23. ],\n",
       "       [23.7],\n",
       "       [25. ],\n",
       "       [21.8],\n",
       "       [20.6],\n",
       "       [21.2],\n",
       "       [19.1],\n",
       "       [20.6],\n",
       "       [15.2],\n",
       "       [ 7. ],\n",
       "       [ 8.1],\n",
       "       [13.6],\n",
       "       [20.1],\n",
       "       [21.8],\n",
       "       [24.5],\n",
       "       [23.1],\n",
       "       [19.7],\n",
       "       [18.3],\n",
       "       [21.2],\n",
       "       [17.5],\n",
       "       [16.8],\n",
       "       [22.4],\n",
       "       [20.6],\n",
       "       [23.9],\n",
       "       [22. ],\n",
       "       [11.9]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = data.iloc[:,[-1]].values\n",
    "label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 1 - Using RFE (Recursive Feature Elimination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1 Initialize the algoritham\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False  True  True  True False  True False False  True False\n",
      "  True]\n",
      "[3 5 4 1 1 1 8 1 2 6 1 7 1]\n"
     ]
    }
   ],
   "source": [
    "#Step 2 Apply RFE\n",
    "from sklearn.feature_selection import RFE\n",
    "selectFeatures = RFE(estimator =model,step=1) #it will remove one feature at each iteration\n",
    "selectFeatures.fit(features,label)\n",
    "print(selectFeatures.support_)\n",
    "print(selectFeatures.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initalize the algoritham\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original lengh of features was (506, 13) and Model selected (506, 3)\n",
      "[False False False  True  True  True False False False False False False\n",
      " False]\n"
     ]
    }
   ],
   "source": [
    "# Apply feature selection by Model\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "selectFeature = SelectFromModel(model)\n",
    "selectFeature.fit(features,label)\n",
    "finalFeaturesSelectByModel = selectFeature.transform(features)\n",
    "print('Original lengh of features was {} and Model selected {}'.format(features.shape,finalFeaturesSelectByModel.shape))\n",
    "print(selectFeature.get_support())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 - Initialize the algoritham\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orignal lenth of features was (506, 13) and Model selected (506, 6)\n",
      "[False False  True False  True  True False False False  True  True False\n",
      "  True]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KiranThakur\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Step 2 - Check using ANOVA\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.feature_selection import f_regression\n",
    "selectFeatures = SelectPercentile(percentile=50, score_func=f_regression)\n",
    "selectFeatures.fit(features,label)\n",
    "finalFeaturesANOVA = selectFeatures.transform(features)\n",
    "print('Orignal lenth of features was {} and Model selected {}'.format(features.shape,finalFeaturesANOVA.shape))\n",
    "print(selectFeatures.get_support())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KiranThakur\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\KiranThakur\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\KiranThakur\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BaggingRegressor(base_estimator=RandomForestRegressor(), n_estimators=101,\n",
       "                 random_state=1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bagging for LinearRegression \n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "algo = LinearRegression()\n",
    "algoKNN = KNeighborsRegressor()\n",
    "algoRandom = RandomForestRegressor()\n",
    "\n",
    "RegressorBag = BaggingRegressor(base_estimator=algo,\n",
    "    n_estimators=101,\n",
    "    random_state=1)\n",
    "\n",
    "\n",
    "\n",
    "RegressorKNNBag = BaggingRegressor(base_estimator=algoKNN,\n",
    "    n_estimators=101,\n",
    "    random_state=1)\n",
    "\n",
    "RegressorRF = BaggingRegressor(base_estimator=algoRandom,\n",
    "    n_estimators=101,\n",
    "    random_state=1)\n",
    "\n",
    "RegressorBag.fit(features,label)\n",
    "RegressorKNNBag.fit(features,label)\n",
    "RegressorRF.fit(features,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7400040955321118"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RegressorBag.score(features,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.953195419776719"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RegressorRF.score(features,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7305285897578123"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RegressorKNNBag.score(features,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9877680670855518"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "housing_predictions = RegressorRF.predict(features)\n",
    "mse = mean_squared_error(label, housing_predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Create Features -\n",
    "# features = np.array([[-5.43942006, 4.12628155, -1.6165014, -0.67288841, -1.42262747,\n",
    "#        -11.44443979304, -49.31238772,  7.61111401, -26.0016879 , -0.5778192 ,\n",
    "#        -0.97491834,  0.41164221, -66.86091034]])\n",
    "\n",
    "\n",
    "# #Predict by Model -\n",
    "# print(\"The price (MEDV) will be: \",RegressorRF.predict(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KiranThakur\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\KiranThakur\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\KiranThakur\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(base_estimator=RandomForestRegressor(), n_estimators=101,\n",
       "                  random_state=1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Boosing for LogistincReggression \n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "algoLR = LinearRegression()\n",
    "algoLRKNN = KNeighborsRegressor()\n",
    "algoLRRandom = RandomForestRegressor()\n",
    "\n",
    "boosterLR = AdaBoostRegressor(base_estimator=algoLR,\n",
    "    n_estimators=101,\n",
    "    random_state=1)\n",
    "\n",
    "boosterLRKNN = AdaBoostRegressor(base_estimator=algoLRKNN,\n",
    "    n_estimators=101,\n",
    "    random_state=1)\n",
    "\n",
    "boosterLRRandom = AdaBoostRegressor(base_estimator=algoLRRandom,\n",
    "    n_estimators=101,\n",
    "    random_state=1)\n",
    "\n",
    "boosterLR.fit(features,label)\n",
    "boosterLRKNN.fit(features,label)\n",
    "boosterLRRandom.fit(features,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7105883022748611"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boosterLR.score(features,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.880697594431185"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boosterLRKNN.score(features,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9943536536430265"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boosterLRRandom.score(features,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Create Features -\n",
    "# features = np.array([[-5.43942006, 4.12628155, -1.6165014, -0.67288841, -1.42262747,\n",
    "#        -11.44443979304, -49.31238772,  7.61111401, -26.0016879 , -0.5778192 ,\n",
    "#        -0.97491834,  0.41164221, -66.86091034]])\n",
    "\n",
    "\n",
    "# #Predict by Model -\n",
    "# print(\"The price (MEDV) will be: \",boosterLRRandom.predict(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.append(np.ones((506,1)).astype(int), features, axis=1) # axis 1 is Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 14)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.000e+00, 6.320e-03, 1.800e+01, 2.310e+00, 0.000e+00, 5.380e-01,\n",
       "       6.575e+00, 6.520e+01, 4.090e+00, 1.000e+00, 2.960e+02, 1.530e+01,\n",
       "       3.969e+02, 4.980e+00])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.740</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.733</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   107.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 14 May 2020</td> <th>  Prob (F-statistic):</th> <td>1.13e-134</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>00:33:48</td>     <th>  Log-Likelihood:    </th> <td> -1499.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   506</td>      <th>  AIC:               </th> <td>   3027.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   492</td>      <th>  BIC:               </th> <td>   3086.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    13</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   36.4697</td> <td>    5.124</td> <td>    7.117</td> <td> 0.000</td> <td>   26.401</td> <td>   46.538</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -0.1081</td> <td>    0.033</td> <td>   -3.285</td> <td> 0.001</td> <td>   -0.173</td> <td>   -0.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.0464</td> <td>    0.014</td> <td>    3.375</td> <td> 0.001</td> <td>    0.019</td> <td>    0.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0220</td> <td>    0.062</td> <td>    0.357</td> <td> 0.721</td> <td>   -0.099</td> <td>    0.143</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    2.6844</td> <td>    0.863</td> <td>    3.112</td> <td> 0.002</td> <td>    0.990</td> <td>    4.379</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>  -17.7231</td> <td>    3.824</td> <td>   -4.634</td> <td> 0.000</td> <td>  -25.237</td> <td>  -10.209</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    3.7971</td> <td>    0.420</td> <td>    9.049</td> <td> 0.000</td> <td>    2.973</td> <td>    4.622</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    0.0011</td> <td>    0.013</td> <td>    0.080</td> <td> 0.937</td> <td>   -0.025</td> <td>    0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>   -1.4633</td> <td>    0.200</td> <td>   -7.321</td> <td> 0.000</td> <td>   -1.856</td> <td>   -1.071</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>    0.3077</td> <td>    0.066</td> <td>    4.634</td> <td> 0.000</td> <td>    0.177</td> <td>    0.438</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   -0.0124</td> <td>    0.004</td> <td>   -3.302</td> <td> 0.001</td> <td>   -0.020</td> <td>   -0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>   -0.9533</td> <td>    0.131</td> <td>   -7.279</td> <td> 0.000</td> <td>   -1.211</td> <td>   -0.696</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>    0.0093</td> <td>    0.003</td> <td>    3.467</td> <td> 0.001</td> <td>    0.004</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>   -0.5253</td> <td>    0.051</td> <td>  -10.336</td> <td> 0.000</td> <td>   -0.625</td> <td>   -0.425</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>177.283</td> <th>  Durbin-Watson:     </th> <td>   1.077</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 774.232</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.516</td>  <th>  Prob(JB):          </th> <td>7.55e-169</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 8.247</td>  <th>  Cond. No.          </th> <td>1.51e+04</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.51e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.740\n",
       "Model:                            OLS   Adj. R-squared:                  0.733\n",
       "Method:                 Least Squares   F-statistic:                     107.8\n",
       "Date:                Thu, 14 May 2020   Prob (F-statistic):          1.13e-134\n",
       "Time:                        00:33:48   Log-Likelihood:                -1499.3\n",
       "No. Observations:                 506   AIC:                             3027.\n",
       "Df Residuals:                     492   BIC:                             3086.\n",
       "Df Model:                          13                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         36.4697      5.124      7.117      0.000      26.401      46.538\n",
       "x1            -0.1081      0.033     -3.285      0.001      -0.173      -0.043\n",
       "x2             0.0464      0.014      3.375      0.001       0.019       0.073\n",
       "x3             0.0220      0.062      0.357      0.721      -0.099       0.143\n",
       "x4             2.6844      0.863      3.112      0.002       0.990       4.379\n",
       "x5           -17.7231      3.824     -4.634      0.000     -25.237     -10.209\n",
       "x6             3.7971      0.420      9.049      0.000       2.973       4.622\n",
       "x7             0.0011      0.013      0.080      0.937      -0.025       0.027\n",
       "x8            -1.4633      0.200     -7.321      0.000      -1.856      -1.071\n",
       "x9             0.3077      0.066      4.634      0.000       0.177       0.438\n",
       "x10           -0.0124      0.004     -3.302      0.001      -0.020      -0.005\n",
       "x11           -0.9533      0.131     -7.279      0.000      -1.211      -0.696\n",
       "x12            0.0093      0.003      3.467      0.001       0.004       0.015\n",
       "x13           -0.5253      0.051    -10.336      0.000      -0.625      -0.425\n",
       "==============================================================================\n",
       "Omnibus:                      177.283   Durbin-Watson:                   1.077\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              774.232\n",
       "Skew:                           1.516   Prob(JB):                    7.55e-169\n",
       "Kurtosis:                       8.247   Cond. No.                     1.51e+04\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.51e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "# Creating an OLS model .....LinearRegressionModel\n",
    "# Step 1 -- All in (Pass all the feature variable available along with the label)\n",
    "# endog ------> label and exog ---- > features\n",
    "# Iteration 1:\n",
    "model1 = sm.OLS(endog=label, exog=features).fit() #to create equation\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.740</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.734</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   117.0</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 14 May 2020</td> <th>  Prob (F-statistic):</th> <td>1.02e-135</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>00:33:48</td>     <th>  Log-Likelihood:    </th> <td> -1499.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   506</td>      <th>  AIC:               </th> <td>   3025.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   493</td>      <th>  BIC:               </th> <td>   3080.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    12</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   36.4355</td> <td>    5.101</td> <td>    7.143</td> <td> 0.000</td> <td>   26.413</td> <td>   46.458</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -0.1081</td> <td>    0.033</td> <td>   -3.289</td> <td> 0.001</td> <td>   -0.173</td> <td>   -0.044</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.0463</td> <td>    0.014</td> <td>    3.394</td> <td> 0.001</td> <td>    0.019</td> <td>    0.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0220</td> <td>    0.062</td> <td>    0.357</td> <td> 0.721</td> <td>   -0.099</td> <td>    0.143</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    2.6879</td> <td>    0.861</td> <td>    3.124</td> <td> 0.002</td> <td>    0.997</td> <td>    4.379</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>  -17.6423</td> <td>    3.684</td> <td>   -4.789</td> <td> 0.000</td> <td>  -24.880</td> <td>  -10.405</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    3.8040</td> <td>    0.410</td> <td>    9.272</td> <td> 0.000</td> <td>    2.998</td> <td>    4.610</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>   -1.4679</td> <td>    0.191</td> <td>   -7.681</td> <td> 0.000</td> <td>   -1.843</td> <td>   -1.092</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>    0.3073</td> <td>    0.066</td> <td>    4.646</td> <td> 0.000</td> <td>    0.177</td> <td>    0.437</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>   -0.0124</td> <td>    0.004</td> <td>   -3.304</td> <td> 0.001</td> <td>   -0.020</td> <td>   -0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   -0.9525</td> <td>    0.130</td> <td>   -7.302</td> <td> 0.000</td> <td>   -1.209</td> <td>   -0.696</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>    0.0093</td> <td>    0.003</td> <td>    3.482</td> <td> 0.001</td> <td>    0.004</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>   -0.5240</td> <td>    0.048</td> <td>  -10.975</td> <td> 0.000</td> <td>   -0.618</td> <td>   -0.430</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>177.739</td> <th>  Durbin-Watson:     </th> <td>   1.076</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 779.114</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.519</td>  <th>  Prob(JB):          </th> <td>6.57e-170</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 8.265</td>  <th>  Cond. No.          </th> <td>1.49e+04</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.49e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.740\n",
       "Model:                            OLS   Adj. R-squared:                  0.734\n",
       "Method:                 Least Squares   F-statistic:                     117.0\n",
       "Date:                Thu, 14 May 2020   Prob (F-statistic):          1.02e-135\n",
       "Time:                        00:33:48   Log-Likelihood:                -1499.3\n",
       "No. Observations:                 506   AIC:                             3025.\n",
       "Df Residuals:                     493   BIC:                             3080.\n",
       "Df Model:                          12                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         36.4355      5.101      7.143      0.000      26.413      46.458\n",
       "x1            -0.1081      0.033     -3.289      0.001      -0.173      -0.044\n",
       "x2             0.0463      0.014      3.394      0.001       0.019       0.073\n",
       "x3             0.0220      0.062      0.357      0.721      -0.099       0.143\n",
       "x4             2.6879      0.861      3.124      0.002       0.997       4.379\n",
       "x5           -17.6423      3.684     -4.789      0.000     -24.880     -10.405\n",
       "x6             3.8040      0.410      9.272      0.000       2.998       4.610\n",
       "x7            -1.4679      0.191     -7.681      0.000      -1.843      -1.092\n",
       "x8             0.3073      0.066      4.646      0.000       0.177       0.437\n",
       "x9            -0.0124      0.004     -3.304      0.001      -0.020      -0.005\n",
       "x10           -0.9525      0.130     -7.302      0.000      -1.209      -0.696\n",
       "x11            0.0093      0.003      3.482      0.001       0.004       0.015\n",
       "x12           -0.5240      0.048    -10.975      0.000      -0.618      -0.430\n",
       "==============================================================================\n",
       "Omnibus:                      177.739   Durbin-Watson:                   1.076\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              779.114\n",
       "Skew:                           1.519   Prob(JB):                    6.57e-170\n",
       "Kurtosis:                       8.265   Cond. No.                     1.49e+04\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.49e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Iteration 2\n",
    "newFeatures1 =features[:,[0,1,2,3,4,5,6,8,9,10,11,12,13]]\n",
    "model1 = sm.OLS(endog=label, exog=newFeatures1).fit() #to create equation\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.740</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.734</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   127.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 14 May 2020</td> <th>  Prob (F-statistic):</th> <td>9.41e-137</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>00:33:48</td>     <th>  Log-Likelihood:    </th> <td> -1499.4</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   506</td>      <th>  AIC:               </th> <td>   3023.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   494</td>      <th>  BIC:               </th> <td>   3074.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    11</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   36.3379</td> <td>    5.089</td> <td>    7.140</td> <td> 0.000</td> <td>   26.338</td> <td>   46.337</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -0.1085</td> <td>    0.033</td> <td>   -3.307</td> <td> 0.001</td> <td>   -0.173</td> <td>   -0.044</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.0457</td> <td>    0.014</td> <td>    3.378</td> <td> 0.001</td> <td>    0.019</td> <td>    0.072</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    2.7196</td> <td>    0.855</td> <td>    3.180</td> <td> 0.002</td> <td>    1.039</td> <td>    4.400</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>  -17.2820</td> <td>    3.540</td> <td>   -4.882</td> <td> 0.000</td> <td>  -24.237</td> <td>  -10.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    3.7898</td> <td>    0.408</td> <td>    9.289</td> <td> 0.000</td> <td>    2.988</td> <td>    4.591</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>   -1.4830</td> <td>    0.186</td> <td>   -7.966</td> <td> 0.000</td> <td>   -1.849</td> <td>   -1.117</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    0.3007</td> <td>    0.063</td> <td>    4.738</td> <td> 0.000</td> <td>    0.176</td> <td>    0.425</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>   -0.0118</td> <td>    0.003</td> <td>   -3.505</td> <td> 0.000</td> <td>   -0.018</td> <td>   -0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>   -0.9465</td> <td>    0.129</td> <td>   -7.324</td> <td> 0.000</td> <td>   -1.200</td> <td>   -0.693</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>    0.0093</td> <td>    0.003</td> <td>    3.475</td> <td> 0.001</td> <td>    0.004</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>   -0.5226</td> <td>    0.048</td> <td>  -10.991</td> <td> 0.000</td> <td>   -0.616</td> <td>   -0.429</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>177.820</td> <th>  Durbin-Watson:     </th> <td>   1.076</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 780.440</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.519</td>  <th>  Prob(JB):          </th> <td>3.38e-170</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 8.271</td>  <th>  Cond. No.          </th> <td>1.47e+04</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.47e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.740\n",
       "Model:                            OLS   Adj. R-squared:                  0.734\n",
       "Method:                 Least Squares   F-statistic:                     127.8\n",
       "Date:                Thu, 14 May 2020   Prob (F-statistic):          9.41e-137\n",
       "Time:                        00:33:48   Log-Likelihood:                -1499.4\n",
       "No. Observations:                 506   AIC:                             3023.\n",
       "Df Residuals:                     494   BIC:                             3074.\n",
       "Df Model:                          11                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         36.3379      5.089      7.140      0.000      26.338      46.337\n",
       "x1            -0.1085      0.033     -3.307      0.001      -0.173      -0.044\n",
       "x2             0.0457      0.014      3.378      0.001       0.019       0.072\n",
       "x3             2.7196      0.855      3.180      0.002       1.039       4.400\n",
       "x4           -17.2820      3.540     -4.882      0.000     -24.237     -10.327\n",
       "x5             3.7898      0.408      9.289      0.000       2.988       4.591\n",
       "x6            -1.4830      0.186     -7.966      0.000      -1.849      -1.117\n",
       "x7             0.3007      0.063      4.738      0.000       0.176       0.425\n",
       "x8            -0.0118      0.003     -3.505      0.000      -0.018      -0.005\n",
       "x9            -0.9465      0.129     -7.324      0.000      -1.200      -0.693\n",
       "x10            0.0093      0.003      3.475      0.001       0.004       0.015\n",
       "x11           -0.5226      0.048    -10.991      0.000      -0.616      -0.429\n",
       "==============================================================================\n",
       "Omnibus:                      177.820   Durbin-Watson:                   1.076\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              780.440\n",
       "Skew:                           1.519   Prob(JB):                    3.38e-170\n",
       "Kurtosis:                       8.271   Cond. No.                     1.47e+04\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.47e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Iteration 3\n",
    "newFeatures2 =features[:,[0,1,2,4,5,6,8,9,10,11,12,13]]\n",
    "model1 = sm.OLS(endog=label, exog=newFeatures2).fit() #to create equation\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.000e+00, 6.320e-03, 1.800e+01, 0.000e+00, 5.380e-01, 6.575e+00,\n",
       "       4.090e+00, 1.000e+00, 2.960e+02, 1.530e+01, 3.969e+02, 4.980e+00])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newFeatures2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_final, X_test_final, y_train_final, y_test_final =train_test_split(newFeatures2,label,test_size=0.2,random_state=95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "finalmodel = LinearRegression()\n",
    "finalmodel.fit(X_train_final,y_train_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7198967323542137"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalmodel.score(X_train_final,y_train_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8013119128106251"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalmodel.score(X_test_final,y_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The price (MEDV) will be:  [[49.01660922]]\n"
     ]
    }
   ],
   "source": [
    "#Create Features -\n",
    "features = np.array([[1, -5.43942006, 4.12628155, -0.67288841, -1.42262747,\n",
    "       -11.44443979304,  7.61111401, -26.0016879 , -0.5778192 ,\n",
    "       -0.97491834,  0.41164221, -66.86091034]])\n",
    "\n",
    "\n",
    "#Predict by Model -\n",
    "print(\"The price (MEDV) will be: \",finalmodel.predict(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.8251374873579795"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "housing_predictions = finalmodel.predict(X_train_final)\n",
    "mse = mean_squared_error(y_train_final, housing_predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
